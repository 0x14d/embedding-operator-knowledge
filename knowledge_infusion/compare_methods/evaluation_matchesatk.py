import glob
import math
import os
import pickle
from typing import List

import pandas as pd

from data_provider.knowledge_graphs.config.knowledge_graph_generator_config import KnowledgeGraphGeneratorType
from knowledge_infusion.compare_methods.compare_methods import matches_at_k_result
from knowledge_infusion.compare_methods.configs.compare_methods_config import MatchesAtKConfig
from knowledge_infusion.graph_embeddings.embedding_types import EmbeddingType

INCLUDE_STD = True


class TableCreator:
    """
    This class processes generated subgraph embedding evaluations generated by
    compare_methods.py from this module
    """

    @staticmethod
    def read_init_pickle(path):
        """
        Reads the pickle generated by CompareMethods
        """
        with open(path + 'results.pickle', 'rb') as f:
            loaded = pickle.load(f)

        for element in loaded:
            # Since the mean is created by pandas over a dataframe the value of
            # elemenent.mean is a series of size 1. We copy the value from series[0]
            # into element.mean to change the datatype from series(len=1) to double
            element.mean = element.mean[0]
        return loaded

    @staticmethod
    def split_by_k(entries: List[matches_at_k_result]):
        """
        Splits the data into bins by k
        """
        k_dict = dict()

        for entry in entries:
            k = entry.k
            if k in k_dict:
                k_dict[k].append(entry)
            else:
                k_dict[k] = [entry]

        return k_dict

    @staticmethod
    def create_df(entries: List[matches_at_k_result]):
        """
        Creates Pandas Dataframe from List of evaluated Embeddings
        """
        kgs = []
        for kgtype in KnowledgeGraphGeneratorType:
            kgs.append(kgtype.value)
        cols = pd.MultiIndex.from_product([kgs, [1, 0], ['euc', 'jac']], names=[
                                          'Representations', 'Use Head', 'Distance'])
        rows = MatchesAtKConfig().embedding_types

        df = pd.DataFrame(None, index=rows, columns=cols)

        for entry in entries:
            if entry.use_head:
                x = 1
            else:
                x = 0
            if math.isnan(entry.mean):
                continue
            k = int(entry.k)
            if INCLUDE_STD:
                df.at[entry.embedding, (entry.representation.value, x, entry.distance_measure)] = str(
                    (entry.mean/k).round(2)) + ' Â± ' + str(round(entry.std[0]/k, 2))
            else:
                df.at[entry.embedding, (entry.representation.value,
                                        x, entry.distance_measure)] = (entry.mean/k).round(2)
        return df

    @staticmethod
    def average_data(og: List[matches_at_k_result], new: List[matches_at_k_result]):
        """This method averages the experinemnt results over mutliple iterations.

        For each result present in the og-List, the same experiment setups in the
        new list are searched for. All the experiments with the same setup are
        then averaged over.

        Args:
            og (List[matches_at_k_result]): First iteration
            new (List[matches_at_k_result]): All following iterations

        Returns:
            List[matches_at_k_result]: First iteration with improved values from
                following iterations
        """
        from statistics import mean, stdev

        for element in og:
            matching = []
            matching.append(element)
            for addition in new:
                if element.distance_measure == addition.distance_measure and element.embedding == addition.embedding and element.representation == addition.representation and element.use_head == addition.use_head:
                    matching.append(addition)
            means = []
            for item in matching:
                means.append(item.mean)
            element.mean = mean(means)
            element.std = [stdev(means)]

        return og

    @staticmethod
    def save_table(table_data, k, data_folder):
        if INCLUDE_STD:
            ending = "with_std"
        else:
            ending = ""

        df = TableCreator.create_df(table_data)
        df = df.drop(columns=[
            KnowledgeGraphGeneratorType.QUANTIFIED_CONDITIONS_WITH_LITERAL,
            KnowledgeGraphGeneratorType.QUANTIFIED_CONDITIONS_WITH_SHORTCUT,
            KnowledgeGraphGeneratorType.QUANTIFIED_CONDITIONS_WITH_SHORTCUT2,
            KnowledgeGraphGeneratorType.QUANTIFIED_CONDITIONS_WITH_SHORTCUT3,
            KnowledgeGraphGeneratorType.QUANTIFIED_CONDITIONS_WITHOUT_SHORTCUT,
            KnowledgeGraphGeneratorType.QUANTIFIED_CONDITIONS_WITHOUT_SHORTCUT2,
            KnowledgeGraphGeneratorType.QUANTIFIED_CONDITIONS_WITHOUT_SHORTCUT3,
            KnowledgeGraphGeneratorType.QUANTIFIED_CONDITIONS_W3,
            KnowledgeGraphGeneratorType.QUANTIFIED_CONDITIONS_W3_WITH_LITERAL
        ])
        df = df.transpose()

        # latex friendly renames of the df
        reps = [KnowledgeGraphGeneratorType[rep.upper(
        )].latex_label for rep in df.index.levels[0]]
        df.index.set_levels(reps, level=0, inplace=True)
        head_replacement = {1: '$h$', 0: '$\\bar{h}$'}
        heads = [head_replacement[head] for head in df.index.levels[1]]
        df.index.set_levels(heads, level=1, inplace=True)
        df.index.set_names("Head", level=1, inplace=True)
        df.columns = [emb.latex_label for emb in df.columns]

        if not os.path.isdir(data_folder):
            os.makedirs(data_folder)

        with open(data_folder + 'k' + k + '_table' + ending + '.csv', 'w') as f:
            df.to_csv(f, sep=";")
        with open(data_folder + 'k' + k + '_table' + ending + '.xlsx', 'wb') as f:
            df.to_excel(f)
        with open(data_folder + 'k' + k + '_table' + ending + '.tex', 'w') as f:
            df.to_latex(f, escape=False)

    @classmethod
    def create_tables_from_evaluation_result_pickle(cls, path):
        """
        Alters the created Dataframes and exports them as CSV, XLSX, Tex
        """

        data = cls.read_init_pickle(path)
        ks = cls.split_by_k(data)

        data_folder = path + "_table_format/"
        for key in ks.keys():
            cls.save_table(ks[key], key, data_folder)

    @classmethod
    def combine_multiple_tables(cls, paths, final_path):
        original_k = dict()
        k_list = dict()

        for i in range(len(paths)):
            path = paths[i]
            data = cls.read_init_pickle(path)
            ks = cls.split_by_k(data)

            for key in ks.keys():
                if i == 0:
                    # First iteration is saved in here
                    original_k[key] = ks[key]
                    k_list[key] = []
                else:
                    for k in ks[key]:
                        # All following iterations are saved here
                        k_list[key].append(k)
        for key in ks.keys():
            # Combine the first and all following iterations
            k = cls.average_data(original_k[key], k_list[key])

            data_folder = final_path + "_tables/"
            cls.save_table(k, key, data_folder)


if __name__ == "__main__":
    base_path = "knowledge_infusion/compare_methods/results/Matches/*/*/*/"
    number_iters = len(glob.glob(base_path + 'iteration*'))
    exps = glob.glob(base_path)

    for exp in exps:
        for std in [True, False]:
            INCLUDE_STD = std
            iterations = glob.glob(exp+'iteration*/')
            for iteration in iterations:
                TableCreator.create_tables_from_evaluation_result_pickle(
                    iteration)
            TableCreator.combine_multiple_tables(iterations, exp)
